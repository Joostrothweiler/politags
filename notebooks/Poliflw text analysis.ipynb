{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def fetch_data(size):\n",
    "    documents = []\n",
    "    per_page = 100\n",
    "    offset = 0\n",
    "    # Paginated fetch\n",
    "    while len(documents) < size:\n",
    "        # Read from the api\n",
    "        url_string = 'https://api.poliflw.nl/v0/search?size={}&from={}'.format(per_page, offset)\n",
    "        request = requests.get(url_string)\n",
    "        json_response = json.loads(request.text)\n",
    "        # Return the array of document items\n",
    "        items = json_response['item']\n",
    "        for item in items:\n",
    "            if len(documents) < size:\n",
    "                documents.append(item)\n",
    "\n",
    "        offset += per_page\n",
    "\n",
    "    return documents\n",
    "\n",
    "\n",
    "def fetch_latest_documents(size=1000):\n",
    "    # Fetch document array\n",
    "    documents = fetch_data(size)\n",
    "    return documents\n",
    "\n",
    "\n",
    "def fetch_single_document(article_id: str):\n",
    "    # Read from the api\n",
    "    url_string = 'https://api.poliflw.nl/v0/combined_index/{}'.format(article_id)\n",
    "    request = requests.get(url_string, auth=(PFL_USER, PFL_PASSWORD))\n",
    "    json_response = json.loads(request.text)\n",
    "\n",
    "    # Fix that makes sure the article json contains an id.\n",
    "    json_response['meta']['_id'] = article_id\n",
    "\n",
    "    # Return article document from poliflow.\n",
    "    return json_response\n",
    "\n",
    "def html2text(html: str) -> float:\n",
    "    \"\"\"\n",
    "    Process the html and transform it to standard text without html tags or weird symbols.\n",
    "    :param html: The html as string.\n",
    "    :return: The parsed html as text without any html tags.\n",
    "    \"\"\"\n",
    "    # TODO: Does not yet successfully handle all html input like &amp;\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    text = soup.get_text().strip().replace('\\n', ' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = fetch_latest_documents(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "from langdetect import DetectorFactory\n",
    "DetectorFactory.seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rothweiler/.local/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://veenendaal.groenlinks.nl/node/112106\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/rothweiler/.local/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://veenendaal.groenlinks.nl/nieuws/oud-papier-hot-veenendaal\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/rothweiler/.local/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://tweedekamer.groenlinks.nl/node/94725\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/rothweiler/.local/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://tweedekamer.groenlinks.nl/node/51910\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/rothweiler/.local/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://raalte.groenlinks.nl/nieuws/stop-dat-miljoen-voor-rondweg-de-zegge-n35-bij-mariÃ«nheem\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/rothweiler/.local/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://www.facebook.com/NowThisFuture/videos/1845143205526851/\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    }
   ],
   "source": [
    "description_lengths = []\n",
    "description_words = []\n",
    "languages = {}\n",
    "\n",
    "for doc in docs:\n",
    "    if 'description' in doc:\n",
    "        text_description = html2text(doc['description'])\n",
    "\n",
    "        description_lengths.append(len(text_description))\n",
    "        description_words.append(len(text_description.split(\" \")))\n",
    "\n",
    "\n",
    "\n",
    "        if len(text_description) > 200:\n",
    "            \n",
    "            try:\n",
    "                lan = detect(text_description)\n",
    "\n",
    "                if not lan in languages:\n",
    "                    languages[lan] = 1\n",
    "                else:\n",
    "                    languages[lan] = languages[lan] + 1\n",
    "            except:\n",
    "                print(text_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249.7085985652218\n",
      "193.35879559462464\n",
      "{'nl': 8201, 'en': 74, 'af': 14, 'de': 5, 'ca': 3, 'fr': 3, 'sv': 1}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "print(np.mean(description_lengths))\n",
    "print(np.mean(description_words))\n",
    "\n",
    "print(languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
